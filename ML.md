https://vdoc.pub/

https://www.pdfdrive.com/

http://danalysis.top/article/stat.html

https://www.pdfdrive.com/search?q=%22Scott+Hartshorn%22&more=true

```
programming-machine-learning-from-coding-to-deep-learning
a-first-course-in-machine-learning(第二版）  13445760_机器学习基础教程
real-world-machine-learning
机器学习系统设计_13580998
vdoc.pub_machine-learning-with-random-forests-and-decision-trees-a-visual-guide-for-beginners
```

# 机器学习理解和实践路径

---

线性建模:最小二乘法

在有着广泛应用的机器学习中，一个重要且普遍的问题是学习或者推断属性变量与相应的响应变量或目标变量之间的函数关系，使得对任何一个属性集合，我们可以预测其响应。例如，我们可能想要建立一个能够执行疾病诊断的模型。为了构建这个模型，需要使用一个数据集，这个数据集是从已知疾病状态（响应，健康或患病）的患者中得到的测量（属性，如血压、心率、体重等）的集合。在完全不同的例子中，我们希望给顾客提出建议。在这种情况下，我们能够建立一个关于某个顾客以前买过物品的描述（属性）和该顾客最终是否喜欢该产品（响应）的模型。这个模型可以帮助我们预测顾客可能喜欢的物品，并因此进行推荐。这一章将涉及许多更重要的应用领域。

13445760_机器学习基础教程

---

building-data-science-applications-with-fastapi-develop-manage-and-deploy-efficient-machine-learning-applications-with-python-1801079218-9781801079211

使用 Python 和FastAPI构建数据科学 API

* 11 NumPy 和 pandas简介
* 12 使用 scikit-learn 训练机器学习模型
* 13 分类数据 朴素贝叶斯模型 346
* 14 实施部署 预测端点 363


pandas 的主要目的是标记数据。

---

第二章 数据的管理和理解

机器学习与R语言

---

机器学习是关于设计自动从数据中提取有价值信息的算法。这里的重点是“自动”，即机器学习关注可应用于许多数据集的通用方法，同时产生有意义的东西。机器学习的核心是三个概念：数据、模型和学习

由于机器学习本质上是数据驱动的，因此数据是机器学习的核心 数据。机器学习的目标是设计通用方法从数据中提取有价值的模式，理想情况下不需要太多特定领域的专业知识。

们可以考虑两种理解机器学习数学的策略：

自下而上：构建从基础到更高级的概念。这通常是更多技术领域（例如数学）的首选方法。这种策略的优点是读者始终能够依赖他们以前学过的概念。不幸的是，对于从业者来说，许多基本概念本身并不是特别有趣，缺乏动力意味着大多数基本定义很快就会被遗忘。

自上而下：从实际需求向下钻取到更基本的需求。这种以目标为导向的方法的优点是，读者始终知道他们为什么需要研究特定的概念，并且有一条清晰的所需知识路径。这种策略的缺点是知识建立在可能不稳定的基础上，读者必须记住一组他们无法理解的单词。

学习自动化

Mathematics for machine learning

---

机器学习颠覆了传统编程：ML 不是向计算机发出指令，而是向计算机提供数据，并要求它弄清楚要做什么：

这种方法早在监督学习出现之前就已经被统计学家使用了。它被称为线性回归。“线性”意味着我们正在追踪一条直线而不是曲线，而“回归”是统计学家的说法：“找到两个变量之间的关系”。

然而，即使你坚持使用监督学习，你也有很多东西可以看，尤其是如果你喜欢计算机科学或统计学的话。虽然这本书专注于神经网络，但还有其他值得学习的算法，其中一些在特定情况下仍然比神经网络工作得更好。举几个例子，看看支持向量机和随机森林。

programming-machine-learning-from-coding-to-deep-learning

通过此书才开始深入机器学习深度学习的知识细节了

---

讨论倍受欢迎的分类器随机森林（Random forest）与支持向量机（Support vector machine，SVM）。

随机森林分类器属于建构于决策树之上的整体学习应用，每一个基本分类器都是一个决策树。这时我们心中就冒出一个疑问：随机森林跟以决策树为基本分类器构成的Bagging 有什么不同？最大的差异应该就是随机的部分，以决策树为基本分类器构成的Bagging 的Boostrap sampling 只有应用在列方向（观测值方向）；随机森林的bootstrap sampling 则是同时应用在列方向（观测值方向）与栏方向（变数方向）。

支持向量机则是一种利用最适化（Optimization）概念在模型的精确度以及推广能力（Generalization ability）中取得一个最佳平衡点的演算法，她在面对小样本，非线性与多维度的资料中广受欢迎。

支持向量机是一种最小化结构风险（Structural risk）的演算法，何谓结构型风险？机器学习的内涵在于假设一个类似模型去逼近真实模型，而量化类似模型与真实模型之间差距的方式，跟我们在计算绩效（准确率）用的概念是相同的，我们用类似模型预测的结果去跟答案比较。许多的分类器可以在训练资料上达到很高的正确率（称作Overfitting），但是却失去应用在实际问题的推广能力（Generalization ability）。

资料科学家将分类器在训练样本可能过度配适的风险称为Empirical risk，分类器的推广能力不足的风险称为Generalization risk，两者的总和即为结构风险，而支持向量机就是在两者之间取得最佳平衡点，进而得到一个在训练资料绩效不错，亦能推广适用的类似模型。

https://ithelp.ithome.com.tw/articles/10187569

---

您无法比较，因为它们是不同类别的事物。深度学习为物体识别、物体分割、图像分类等复杂问题提供了完整的解决方案。SVM 只是一个分类器。分类器只是深度学习系统的一个组成部分，几乎总是以“神经网络”的形式出现。

它们基本上是完全不相关的。深度学习通过进行矩阵乘法来学习一系列非线性变换，然后将其输入到 ReLU 等“激活函数”中。SVM 根据类应该远离边界的标准找到一组“支持向量”或数据点，它们位于并定义决策边界附近。

深度学习是以分层方式学习越来越抽象的表示。每层都从下一层馈送，然后将输出发送到上一层，依此类推。在视觉应用的情况下，这个过程导致层次较高的神经元对特定的完整对象或场景敏感。

另一方面，支持向量机 (SVM) 是基于找到离任一侧最近点（支持向量）尽可能远的分裂边界（线性可分情况下的超平面）。换句话说，给定一组属于 A 和 B 两个类中的任何一个的点。SVM 是关于找到通过点之间的边界，例如将空间划分为 A 侧和 B 侧，同时保持最大距离远离任何一侧最近的点。靠近决策边界的那些点被称为支持向量，因为它们是“支持”边界的那些点。仅支持向量用于计算边界。支持向量机也可以以分层方式堆叠，形成支持向量机网络的深层变体。因此，DL 基于这种堆叠层这一事实意味着可以制作一个充满 SVM 的深度神经网络。

https://www.quora.com/What-is-the-difference-between-deep-learning-and-SVM

---

除非您以一种以上的方式学习它，否则您不会理解任何东西。马文·明斯基

---

构建分类器并进行预测，首要任务是选择用于构建分类器的分类算法。有许多算法可用，每种算法都针对不同的数据和部署要求各有利弊。附录提供了算法表及其属性比较。你将在整本书中使用这张表来选择算法来尝试解决不同的问题。在本节中，算法的选择不是必需的；在下一章中，您将学习如何正确衡量算法的性能并选择最适合该工作的算法。

real-world-machine-learning

---

机器学习正迅速成为计算科学中一般实践、研究和开发活动中最重要的领域之一。这反映在致力于该主题的学术研究领域的规模以及主要国际银行和金融机构以及微软、谷歌、雅虎和亚马逊等公司积极招聘机器学习专家。这种增长可以部分**解释为我们能够对世界进行的测量的数量和多样性的增加**。一个特别引人入胜的例子来自于第一批基因组测序之后出现的新生物测量技术浪潮。现在有可能以不久前还难以想象的方式测量生物体的详细分子状态。这样的测量远远超出了我们对这些生物体的理解，机器学习技术已经大量参与了从它们中提取有用结构的过程。

a-first-course-in-machine-learning

----


# 传统的机器学习之路

通过上面的了解之后，想深入了解传统机器学习方法。首先遇到bigml.com，大概看了一下介绍，没怎么明白，但给我一点启示。然后浏览了一下《机器学习系统设计_13580998》又领悟了一些，但根据前面programming-machine-learning-from-coding-to-deep-learning这本书的最后的提示，去了解svm和随机深林。svm有个大概的意思，但决策树随机森林还没有，所以找到了《vdoc.pub_machine-learning-with-random-forests-and-decision-trees-a-visual-guide-for-beginners》这本书，随机森林算是有了了解。

http://www.fairlynerdy.com/

# 想到了一个实用的机器学习项目，就是通过身高和体重预测衣服裤子的型号

https://towardsdatascience.com/machine-learning-project-9-predict-weight-based-on-height-and-gender-9ed47285bcbb

# 这系列17篇文章，明明白白的机器学习入门了！！用实际例子理解如何使用机器学习。（非深度学习）

https://medium.com/@omairaasim

# PostgresML, juice

https://postgresml.org/

https://github.com/spearow/juice

# digitalocean介绍机器学习

https://www.digitalocean.com/community/tutorials/an-introduction-to-machine-learning

# 机器学习模型部署为服务的相关链接

https://www.bentoml.com/

https://streamlit.io/

https://modelserving.com/

https://mathdatasimplified.com/

https://www.fast.ai/

https://www.kaggle.com/

https://towardsdatascience.com/step-by-step-approach-to-build-your-machine-learning-api-using-fast-api-21bd32f2bbdb

https://github.com/keitazoumana/Fastapi-tutorial/blob/master/project_structure.txt

https://www.kaggle.com/datasets/imakash3011/customer-personality-analysis

# kaggle上的“根据症状预测疾病“

https://www.kaggle.com/datasets?search=symptom

# rnn

https://colah.github.io/posts/2015-08-Understanding-LSTMs/

# symptoms based disease prediction using machine learning techniques

https://www.geeksforgeeks.org/disease-prediction-using-machine-learning/

# 深度学习fastai + bentoml

https://modelserving.com/blog/productionizing-fastai-models-with-bentoml

https://docs.fast.ai/


# 矢量搜索，相似性学习Similarity Learning

因为偶然的机会看到kern.ai这个项目，根据kern.ai又看到了qdrant（矢量搜索，相似搜索，语义搜索）以及sbert，以及max.io，基本上就进入了深度学习的大门。

https://qdrant.tech/

https://qdrant.tech/articles/neural-search-tutorial/

# Encoder 编码器

# embeddings

https://www.featureform.com/post/the-definitive-guide-to-embeddings

https://daleonai.com/embeddings-explained

# 神经网络与线性代数

https://leemeng.tw/deep-learning-for-everyone-understand-neural-net-and-linear-algebra.html

# 矩阵，矢量，张量，线性代数

```
线性代数向量分析 作 者 ：（日）小西荣一，深见哲造等著；刘俊山译
计算实习 高等部分 第1分册 线性代数计算 作 者 ：王德人等编 出版发行 : 北京：高等教育出版社 , 1959.10
矩阵 作 者 ：贾广聚编 出版发行 : 哈尔滨：黑龙江人民出版社 , 1980.08
矢量、张量与矩阵 作 者 ：（美）阿弗肯（Arfken，G.）著；曹富田译 出版发行 : 北京：计量出版社 , 1986.02
```
https://www.youtube.com/watch?v=v2uHiBH85mk

# BERT基于注意力的模型transformer，已经战胜了cnn，rnn之类。

https://en.wikipedia.org/wiki/BERT_(language_model)

https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)

https://quaterion.qdrant.tech/getting_started/why_quaterion.html#why-quaterion

# Quaterion

https://quaterion.qdrant.tech/

# pytorch

https://pytorch.org/tutorials/beginner/basics/intro.html

https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html

神经网络由对数据执行操作的层/模块组成。

nn.Sequential是一个有序的模块容器。数据按照定义的顺序通过所有模块。

# 什么是神经网络？

https://www.spiceworks.com/tech/artificial-intelligence/articles/what-is-a-neural-network/

什么是神经网络？ 神经网络是一种软件解决方案，它利用机器学习 (ML)算法来“模仿”人脑的操作。与传统计算机相比，神经网络更有效地处理数据，并具有改进的模式识别和解决问题的能力。神经网络也称为人工神经网络 (ANN) 或模拟神经网络 (SNN)。

http://wiki.pathmind.com/neural-network

神经网络定义：神经网络是一组算法，松散地模仿人脑，旨在识别模式。他们通过一种机器感知、标记或聚类原始输入来解释感官数据。他们识别的模式是数字的，包含在向量中，所有现实世界的数据，无论是图像、声音、文本还是时间序列，都必须转换成向量。神经网络帮助我们进行聚类和分类。您可以将它们视为您存储和管理的数据之上的聚类和分类层。它们有助于根据示例输入之间的相似性对未标记的数据进行分组，并在有标记数据集进行训练时对数据进行分类。（神经网络还可以提取提供给其他算法进行聚类和分类的特征；因此您可以将深度神经网络视为涉及强化学习、分类和回归算法的大型机器学习应用程序的组件。）

深度学习是我们为“堆叠神经网络”使用的名称；也就是说，由多层组成的网络。

比赛本身涉及许多步骤，每个步骤都类似于之前和之后的步骤。就像跑步者一样，我们会一遍又一遍地进行重复的动作以到达终点。神经网络的每一步都涉及猜测、误差测量和权重的轻微更新，以及对系数的增量调整，因为它慢慢学会关注最重要的特征。

这是因为神经网络是在无知中诞生的。它不知道哪些权重和偏差将最好地转换输入以做出正确的猜测。它必须从猜测开始，然后随着它从错误中学习，依次尝试做出更好的猜测。（您可以将神经网络视为科学方法的缩影，检验假设并再次尝试——只是它是蒙着眼睛的科学方法。或者像孩子一样：他们生来就知之甚少，并且通过接触生活经验，他们慢慢学会解决世界上的问题。对于神经网络，数据是唯一的经验。）

深度学习中学习的本质不外乎：根据模型产生的误差调整模型的权重，直到不能再减少误差。

# 人工智能 (AI) 、机器学习、深度学习

http://wiki.pathmind.com/

http://wiki.pathmind.com/ai-vs-machine-learning-vs-deep-learning

机器学习的“学习”部分是指机器学习算法试图沿着某个维度进行优化；即，他们通常会尽量减少错误或最大化他们的预测为真的可能性。这有三个名称：误差函数、损失函数或目标函数，因为算法有一个目标……当有人说他们正在使用机器学习算法时，你可以通过询问来了解其价值的要点：目标函数是什么？

# Transformers Take Over Object Detection

微软的DyHead使用 Transformer 主干实现了最先进的对象检测。

https://blog.roboflow.com/transformers-take-over-object-detection/

# Attention Is All You Need

我们提出了一种新的简单网络架构 Transformer，它完全基于注意力机制，完全摒弃了递归和卷积。对两个机器翻译任务的实验表明，这些模型在质量上更优越，同时更可并行化，并且需要的训练时间显着减少

https://arxiv.org/abs/1706.03762

# pytorch, tensorflow, keras

https://keras.io/examples/

# 深度学习所需的矩阵微积分 （2018 年 2 月）

https://explained.ai/matrix-calculus/index.html

https://explained.ai/

# 微积分是变化的数学。

https://machinelearningmastery.com/calculus-for-machine-learning/

为什么微积分对机器学习很重要？

那么，为什么微积分被如此多地用来描述机器学习算法呢？

机器学习基于寻找描述数据的最佳方式，因此我们可以使用相同的方式来预测我们未见过的数据。为了考虑什么是最优的，什么不是，微积分是我们使用的工具。

微积分是变化的数学。

它提供了有用的工具来检查事物将如何因其他事物的扰动而发生变化。它还有助于我们理解算法的因果关系。

微积分并不晦涩。它是建模行为的语言。如果没有微积分，我们将无法完全理解以下技术：

神经网络中的反向传播
使用最优最小二乘进行回归
拟合概率模型中的期望最大化

Calculus for Machine Learning - Understanding the Language of Mathematics

# Sequential

https://analyticsindiamag.com/a-tutorial-on-sequential-machine-learning/

```
from tensorflow.keras.models import Sequential
model = Sequential()
```

# 放弃传统的机器学习方法可以吗？

https://analyticsindiamag.com/is-it-okay-to-abandon-traditional-machine-learning-approaches/

# tabular data （传统机器学习），文本，图片，视频（深度学习）

昨晚看到《伤寒论新解》273页这张图，启发了我思考tabular data，也就是表格数据。突然发现传统机器学习是针对tabular data的，而深度学习是针对文本，图片这种序列数据的。而传统机器学习目前最大优胜者是XGBoost，而深度学习最大优胜者是Transformer。

<img width="316" alt="image" src="https://user-images.githubusercontent.com/2258120/183234590-38856ad4-025c-402c-8c2f-7188606793e5.png">

# Tabular Data: Deep Learning is Not All You Need

解决现实生活中的数据科学问题的一个关键要素是选择要使用的模型类型。树集成模型（例如 XGBoost）通常推荐用于表格数据的分类和回归问题。然而，最近提出了几种表格数据的深度学习模型，声称在某些用例上优于 XGBoost。本文通过在各种数据集上将新的深度模型与 XGBoost 进行严格比较，探讨这些深度模型是否应该成为表格数据的推荐选项。除了系统地比较它们的性能之外，我们还考虑了它们所需的调整和计算。我们的研究表明，XGBoost 在数据集上优于这些深度模型，包括在提出深度模型的论文中使用的数据集。我们还证明了 XGBoost 需要的调整要少得多。

https://arxiv.org/abs/2106.03253

深度学习在自然语言处理、计算机视觉和其他领域取得了惊人的成功，但是当涉及到其他情况下常见的数据类型时，尤其是在数据通常较小且来源和类型混合的情况下（例如人口统计、社会科学，生物数据），对于复杂的深度学习架构来说，结果大多并不令人印象深刻。特别是，DL 方法似乎无法始终与梯度提升（例如 XGBoost）等常见机器学习 (ML) 方法竞争，更不用说始终击败。在这里，我提供了一些更新，因为还有几篇文章继续战斗。

https://m-clark.github.io/posts/2022-04-01-more-dl-for-tabular/

“表格数据”意义不大。这取决于表中的数据。神经网络被设计（并且是有效的）来解决大量数据的问题，您需要为这些数据构建要处理的数据的有效中间表示。如果您正在处理年龄或价格，您实际上并不需要中间表示来解释这些数据，因此即使神经网络可以完成这项工作，也不会使用它们的主要质量。如果你在处理声音、图像，你可以有大量的数据，而原始数据是毫无用处的，你需要一个中间表示，所以神经网络会更有效率。所以直觉是：如果你需要一个中间表示，使用神经网络。如果您不这样做，请先尝试其他方法。

https://www.reddit.com/r/MachineLearning/comments/lzoqjg/comment/gq3acxz/

# An Introduction to Deep Learning for Tabular Data

有一种强大的技术正在赢得 Kaggle 比赛，并在 Google（根据 Jeff Dean的说法）、Pinterest和Instacart广泛使用，但许多人甚至没有意识到这是可能的：将深度学习用于表格数据，以及特别是为分类变量创建嵌入。

https://www.fast.ai/2018/04/29/categorical-embeddings/

到目前为止，我们已经看到了深度学习的各种 应用。所有这些应用程序都涉及图像数据，深度学习在它们方面做得很好。本文的目的是了解深度学习是否也可以很好地处理表格数据。为此，我们将其性能与随机森林的性能进行比较。

https://becominghuman.ai/ml-vs-dl-for-tabular-data-8ae2992980eb

KNN 使用我们童年时可能学过的一些数学来捕捉相似性（有时称为距离、接近度或接近度）的概念——计算图上点之间的距离。

https://towardsdatascience.com/machine-learning-basics-with-the-k-nearest-neighbors-algorithm-6a6e71d01761

# 数据分析，测量，相似性

数学是数据分析的工具和理论，测量长度，长度就是特征，发现相似性。启示数学就是进行数据分析，包括大数据分析，寻找相似性，进行分类等。

《数据的收集方法和应用 2》 作  者 : （日）铁健司，（日）谷津进编；邸宏译 出版日期 : 1987.04

https://user-images.githubusercontent.com/2258120/184561624-cd2b7931-e7e9-4f7a-b0d4-a3568ec35765.png

在质量管理活动中，上至管理的领导者，下至从业人员都**坚持不懈地应用统计方法**，并努力根据质量管理的思想，**以数据为基础进行管理和改善**。

人们已经承认质量管理小组成员首先要学习这种工具的应用方法，在质量管理的各个阶段中实际应用这种工具解决问题并已大见成效。这些成果本身也从另一个侧面说明了质量管理小组活动并不是光靠精神战术所能奏效的。

https://user-images.githubusercontent.com/2258120/184561825-d427011d-0ac4-4807-b3d1-a14cce708786.png

# 极坐标。求两点之间的距离cos0

https://tutorial.math.lamar.edu/Classes/CalcII/PolarCoordinates.aspx

https://cloud.tencent.com/developer/article/1707535

https://cloud.google.com/blog/topics/developers-practitioners/find-anything-blazingly-fast-googles-vector-search-technology

https://www.mathsisfun.com/data/index.html

# 有趣的数学网站

https://www.mathsisfun.com/

# 直角坐标是矩形的自然坐标，极坐标是圆的自然坐标。

https://towardsdatascience.com/work-smarter-not-harder-when-building-neural-networks-6f4aa7c5ee61

# 一切都是回归： 模型是对现实世界复杂性的抽象和简化。由于它们是简化的，它们总是错误的，但它们可能会捕捉到一些重要的想法。

https://medium.com/towards-data-science/everything-is-just-a-regression-5a3bf22c459c

# 微分方程

尽管层通常是简单的函数（例如 relu(Wx+b)) 一般来说，它们可以是任何可微的函数。

因此，我们可以将微分方程用作神经网络中的一层。这真的很整洁，有几个原因：

微分方程是所有物理定律的基本语言。
除了物理和化学，微分方程是描述复杂系统行为的重要工具。在我们的神经网络中使用微分方程模型可以将这些模型与神经网络方法相结合。

https://towardsdatascience.com/differential-equations-as-a-neural-network-layer-ac3092632255

微分方程在物理、化学、生物、医学、金融和建筑等很多领域都有广泛的应用，因为这些领域中有时用数学模型，即微分方程来描述实际问题。因此，研究微分方程很有必要。

# 机器学习最简单理解的入门教程，从这个教程我理解了ml，就像qdrant理解了transformer一样。

https://www.kaggle.com/learn/intro-to-machine-learning

https://www.kaggle.com/embed/dansbecker/how-models-work?cellIds=1

本课程将让您在经历以下场景时构建模型：

你的表弟在房地产上投机赚了数百万美元。由于您对数据科学的兴趣，他提出与您成为业务合作伙伴。他将提供资金，您将提供预测各种房屋价值的模型。

你问你的表弟他过去是如何预测房地产价值的，他说这只是直觉。但更多的质疑表明，他已经从他过去看到的房屋中识别出价格模式，并且他使用这些模式来预测他正在考虑的新房子。

机器学习的工作方式相同。我们将从一个称为决策树的模型开始。有更好的模型可以提供更准确的预测。但是决策树很容易理解，它们是数据科学中一些最佳模型的基本构建块。

为简单起见，我们将从最简单的决策树开始。

https://www.kaggle.com/embed/dansbecker/basic-data-exploration?cellIds=1-10

https://www.kaggle.com/embed/dansbecker/your-first-machine-learning-model?cellIds=1-16

https://www.kaggle.com/embed/dansbecker/model-validation?cellIds=1-7

https://www.kaggle.com/embed/dansbecker/underfitting-and-overfitting?cellIds=1-7

https://www.kaggle.com/embed/dansbecker/random-forests?cellIds=1-5

从一个例子开始，投资者和数据科学家合作，从决策树开始，明确指出决策树是模型的类型。DataFrame是ml学习的基础结构（跟先前我理解taulardata一样）

# ANN

ANN就是根据伤寒金匮按照病的方式对症状进行分割，然后再在该病的空间里进行方证匹配。提高效率，比完全从症状的角度进行方证匹配效率更高，更容易掌握。

https://cloud.google.com/vertex-ai/docs/matching-engine/ann-service-overview?hl=zh-cn

https://ai.googleblog.com/2020/07/announcing-scann-efficient-vector.html

ANN的方法分为三大类：基于树的方法、哈希方法、矢量量化方法。 brute-force搜索的方式是在全空间进行搜索，为了加快查找的速度，几乎所有的ANN方法都是通过对全空间分割，将其分割成很多小的子空间，在搜索的时候，通过某种方式，快速锁定在某一（几）子空间，然后在该（几个）子空间里做遍历。

# input 输入，输入数据的结构

不同的算法适用于不同的数据输入，不同的任务需要不同的数据和算法，大多数资料重在讲算法，却忽略了算法的输入，即数据，以及数据的结构。所以了解喂给算法或者说模型的数据是什么样的结构，对于了解学习机器学习，分清其中的差别至关重要。比如ml适合tabluar形状的是数据，而dl适合序列化的数据，比如文本，但其中需要更深入的理解这些结构和对应的算法模型。

https://bi-kring.nl/192-data-science/1206-why-the-right-data-input-is-key-a-machine-learning-example

机器学习不是黑魔法。一个简单的定义是将学习算法应用于数据以揭示输入的有用方面。不过，这个过程显然有两个部分：算法本身以及正在处理和输入的数据。

算法至关重要，不断调整和改进它们会对解决方案的成功产生重大影响。然而，这些只是对数据的数学实验。关键位是数据本身。很简单，这些算法不能很好地处理较差的数据量，并且数据不足会使系统营养不良，最终，系统会渴望更多。随着更多数据的消耗，系统可以得到更充分的训练，结果也更强大。

https://thecleverprogrammer.com/2021/11/29/how-to-give-inputs-to-a-machine-learning-model/

https://livebook.manning.com/concept/machine-learning/input-feature


