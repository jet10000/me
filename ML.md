https://vdoc.pub/

https://www.pdfdrive.com/

http://danalysis.top/article/stat.html

https://www.pdfdrive.com/search?q=%22Scott+Hartshorn%22&more=true

```
programming-machine-learning-from-coding-to-deep-learning
a-first-course-in-machine-learning(第二版）  13445760_机器学习基础教程
real-world-machine-learning
机器学习系统设计_13580998
vdoc.pub_machine-learning-with-random-forests-and-decision-trees-a-visual-guide-for-beginners
```

# 机器学习理解和实践路径

---

线性建模:最小二乘法

在有着广泛应用的机器学习中，一个重要且普遍的问题是学习或者推断属性变量与相应的响应变量或目标变量之间的函数关系，使得对任何一个属性集合，我们可以预测其响应。例如，我们可能想要建立一个能够执行疾病诊断的模型。为了构建这个模型，需要使用一个数据集，这个数据集是从已知疾病状态（响应，健康或患病）的患者中得到的测量（属性，如血压、心率、体重等）的集合。在完全不同的例子中，我们希望给顾客提出建议。在这种情况下，我们能够建立一个关于某个顾客以前买过物品的描述（属性）和该顾客最终是否喜欢该产品（响应）的模型。这个模型可以帮助我们预测顾客可能喜欢的物品，并因此进行推荐。这一章将涉及许多更重要的应用领域。

13445760_机器学习基础教程

---

building-data-science-applications-with-fastapi-develop-manage-and-deploy-efficient-machine-learning-applications-with-python-1801079218-9781801079211

使用 Python 和FastAPI构建数据科学 API

* 11 NumPy 和 pandas简介
* 12 使用 scikit-learn 训练机器学习模型
* 13 分类数据 朴素贝叶斯模型 346
* 14 实施部署 预测端点 363


pandas 的主要目的是标记数据。

---

第二章 数据的管理和理解

机器学习与R语言

---

机器学习是关于设计自动从数据中提取有价值信息的算法。这里的重点是“自动”，即机器学习关注可应用于许多数据集的通用方法，同时产生有意义的东西。机器学习的核心是三个概念：数据、模型和学习

由于机器学习本质上是数据驱动的，因此数据是机器学习的核心 数据。机器学习的目标是设计通用方法从数据中提取有价值的模式，理想情况下不需要太多特定领域的专业知识。

们可以考虑两种理解机器学习数学的策略：

自下而上：构建从基础到更高级的概念。这通常是更多技术领域（例如数学）的首选方法。这种策略的优点是读者始终能够依赖他们以前学过的概念。不幸的是，对于从业者来说，许多基本概念本身并不是特别有趣，缺乏动力意味着大多数基本定义很快就会被遗忘。

自上而下：从实际需求向下钻取到更基本的需求。这种以目标为导向的方法的优点是，读者始终知道他们为什么需要研究特定的概念，并且有一条清晰的所需知识路径。这种策略的缺点是知识建立在可能不稳定的基础上，读者必须记住一组他们无法理解的单词。

学习自动化

Mathematics for machine learning

---

机器学习颠覆了传统编程：ML 不是向计算机发出指令，而是向计算机提供数据，并要求它弄清楚要做什么：

这种方法早在监督学习出现之前就已经被统计学家使用了。它被称为线性回归。“线性”意味着我们正在追踪一条直线而不是曲线，而“回归”是统计学家的说法：“找到两个变量之间的关系”。

然而，即使你坚持使用监督学习，你也有很多东西可以看，尤其是如果你喜欢计算机科学或统计学的话。虽然这本书专注于神经网络，但还有其他值得学习的算法，其中一些在特定情况下仍然比神经网络工作得更好。举几个例子，看看支持向量机和随机森林。

programming-machine-learning-from-coding-to-deep-learning

通过此书才开始深入机器学习深度学习的知识细节了

---

讨论倍受欢迎的分类器随机森林（Random forest）与支持向量机（Support vector machine，SVM）。

随机森林分类器属于建构于决策树之上的整体学习应用，每一个基本分类器都是一个决策树。这时我们心中就冒出一个疑问：随机森林跟以决策树为基本分类器构成的Bagging 有什么不同？最大的差异应该就是随机的部分，以决策树为基本分类器构成的Bagging 的Boostrap sampling 只有应用在列方向（观测值方向）；随机森林的bootstrap sampling 则是同时应用在列方向（观测值方向）与栏方向（变数方向）。

支持向量机则是一种利用最适化（Optimization）概念在模型的精确度以及推广能力（Generalization ability）中取得一个最佳平衡点的演算法，她在面对小样本，非线性与多维度的资料中广受欢迎。

支持向量机是一种最小化结构风险（Structural risk）的演算法，何谓结构型风险？机器学习的内涵在于假设一个类似模型去逼近真实模型，而量化类似模型与真实模型之间差距的方式，跟我们在计算绩效（准确率）用的概念是相同的，我们用类似模型预测的结果去跟答案比较。许多的分类器可以在训练资料上达到很高的正确率（称作Overfitting），但是却失去应用在实际问题的推广能力（Generalization ability）。

资料科学家将分类器在训练样本可能过度配适的风险称为Empirical risk，分类器的推广能力不足的风险称为Generalization risk，两者的总和即为结构风险，而支持向量机就是在两者之间取得最佳平衡点，进而得到一个在训练资料绩效不错，亦能推广适用的类似模型。

https://ithelp.ithome.com.tw/articles/10187569

---

您无法比较，因为它们是不同类别的事物。深度学习为物体识别、物体分割、图像分类等复杂问题提供了完整的解决方案。SVM 只是一个分类器。分类器只是深度学习系统的一个组成部分，几乎总是以“神经网络”的形式出现。

它们基本上是完全不相关的。深度学习通过进行矩阵乘法来学习一系列非线性变换，然后将其输入到 ReLU 等“激活函数”中。SVM 根据类应该远离边界的标准找到一组“支持向量”或数据点，它们位于并定义决策边界附近。

深度学习是以分层方式学习越来越抽象的表示。每层都从下一层馈送，然后将输出发送到上一层，依此类推。在视觉应用的情况下，这个过程导致层次较高的神经元对特定的完整对象或场景敏感。

另一方面，支持向量机 (SVM) 是基于找到离任一侧最近点（支持向量）尽可能远的分裂边界（线性可分情况下的超平面）。换句话说，给定一组属于 A 和 B 两个类中的任何一个的点。SVM 是关于找到通过点之间的边界，例如将空间划分为 A 侧和 B 侧，同时保持最大距离远离任何一侧最近的点。靠近决策边界的那些点被称为支持向量，因为它们是“支持”边界的那些点。仅支持向量用于计算边界。支持向量机也可以以分层方式堆叠，形成支持向量机网络的深层变体。因此，DL 基于这种堆叠层这一事实意味着可以制作一个充满 SVM 的深度神经网络。

https://www.quora.com/What-is-the-difference-between-deep-learning-and-SVM

---

除非您以一种以上的方式学习它，否则您不会理解任何东西。马文·明斯基

---

构建分类器并进行预测，首要任务是选择用于构建分类器的分类算法。有许多算法可用，每种算法都针对不同的数据和部署要求各有利弊。附录提供了算法表及其属性比较。你将在整本书中使用这张表来选择算法来尝试解决不同的问题。在本节中，算法的选择不是必需的；在下一章中，您将学习如何正确衡量算法的性能并选择最适合该工作的算法。

real-world-machine-learning

---

机器学习正迅速成为计算科学中一般实践、研究和开发活动中最重要的领域之一。这反映在致力于该主题的学术研究领域的规模以及主要国际银行和金融机构以及微软、谷歌、雅虎和亚马逊等公司积极招聘机器学习专家。这种增长可以部分**解释为我们能够对世界进行的测量的数量和多样性的增加**。一个特别引人入胜的例子来自于第一批基因组测序之后出现的新生物测量技术浪潮。现在有可能以不久前还难以想象的方式测量生物体的详细分子状态。这样的测量远远超出了我们对这些生物体的理解，机器学习技术已经大量参与了从它们中提取有用结构的过程。

a-first-course-in-machine-learning

----


# 传统的机器学习之路

通过上面的了解之后，想深入了解传统机器学习方法。首先遇到bigml.com，大概看了一下介绍，没怎么明白，但给我一点启示。然后浏览了一下《机器学习系统设计_13580998》又领悟了一些，但根据前面programming-machine-learning-from-coding-to-deep-learning这本书的最后的提示，去了解svm和随机深林。svm有个大概的意思，但决策树随机森林还没有，所以找到了《vdoc.pub_machine-learning-with-random-forests-and-decision-trees-a-visual-guide-for-beginners》这本书，随机森林算是有了了解。

http://www.fairlynerdy.com/

# 想到了一个实用的机器学习项目，就是通过身高和体重预测衣服裤子的型号

https://towardsdatascience.com/machine-learning-project-9-predict-weight-based-on-height-and-gender-9ed47285bcbb

# 这系列17篇文章，明明白白的机器学习入门了！！用实际例子理解如何使用机器学习。（非深度学习）

https://medium.com/@omairaasim

# PostgresML, juice

https://postgresml.org/

https://github.com/spearow/juice

# digitalocean介绍机器学习

https://www.digitalocean.com/community/tutorials/an-introduction-to-machine-learning

# 机器学习模型部署为服务的相关链接

https://www.bentoml.com/

https://streamlit.io/

https://modelserving.com/

https://mathdatasimplified.com/

https://www.fast.ai/

https://www.kaggle.com/

https://towardsdatascience.com/step-by-step-approach-to-build-your-machine-learning-api-using-fast-api-21bd32f2bbdb

https://github.com/keitazoumana/Fastapi-tutorial/blob/master/project_structure.txt

https://www.kaggle.com/datasets/imakash3011/customer-personality-analysis

# kaggle上的“根据症状预测疾病“

https://www.kaggle.com/datasets?search=symptom

# rnn

https://colah.github.io/posts/2015-08-Understanding-LSTMs/

# symptoms based disease prediction using machine learning techniques

https://www.geeksforgeeks.org/disease-prediction-using-machine-learning/

# 深度学习fastai + bentoml

https://modelserving.com/blog/productionizing-fastai-models-with-bentoml

https://docs.fast.ai/


# 矢量搜索，相似性学习Similarity Learning

https://qdrant.tech/

https://qdrant.tech/articles/neural-search-tutorial/

# Encoder 编码器

# embeddings

https://www.featureform.com/post/the-definitive-guide-to-embeddings

https://daleonai.com/embeddings-explained

# 神经网络与线性代数

https://leemeng.tw/deep-learning-for-everyone-understand-neural-net-and-linear-algebra.html

# 矩阵，矢量，张量，线性代数

```
线性代数向量分析 作 者 ：（日）小西荣一，深见哲造等著；刘俊山译
计算实习 高等部分 第1分册 线性代数计算 作 者 ：王德人等编 出版发行 : 北京：高等教育出版社 , 1959.10
矩阵 作 者 ：贾广聚编 出版发行 : 哈尔滨：黑龙江人民出版社 , 1980.08
矢量、张量与矩阵 作 者 ：（美）阿弗肯（Arfken，G.）著；曹富田译 出版发行 : 北京：计量出版社 , 1986.02
```
https://www.youtube.com/watch?v=v2uHiBH85mk

# BERT基于注意力的模型transformer，已经战胜了cnn，rnn之类。

https://en.wikipedia.org/wiki/BERT_(language_model)

https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)

https://quaterion.qdrant.tech/getting_started/why_quaterion.html#why-quaterion

# Quaterion

https://quaterion.qdrant.tech/

# pytorch

https://pytorch.org/tutorials/beginner/basics/intro.html

https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html

神经网络由对数据执行操作的层/模块组成。

nn.Sequential是一个有序的模块容器。数据按照定义的顺序通过所有模块。

# 什么是神经网络？

https://www.spiceworks.com/tech/artificial-intelligence/articles/what-is-a-neural-network/

什么是神经网络？ 神经网络是一种软件解决方案，它利用机器学习 (ML)算法来“模仿”人脑的操作。与传统计算机相比，神经网络更有效地处理数据，并具有改进的模式识别和解决问题的能力。神经网络也称为人工神经网络 (ANN) 或模拟神经网络 (SNN)。

http://wiki.pathmind.com/neural-network

神经网络定义：神经网络是一组算法，松散地模仿人脑，旨在识别模式。他们通过一种机器感知、标记或聚类原始输入来解释感官数据。他们识别的模式是数字的，包含在向量中，所有现实世界的数据，无论是图像、声音、文本还是时间序列，都必须转换成向量。神经网络帮助我们进行聚类和分类。您可以将它们视为您存储和管理的数据之上的聚类和分类层。它们有助于根据示例输入之间的相似性对未标记的数据进行分组，并在有标记数据集进行训练时对数据进行分类。（神经网络还可以提取提供给其他算法进行聚类和分类的特征；因此您可以将深度神经网络视为涉及强化学习、分类和回归算法的大型机器学习应用程序的组件。）

深度学习是我们为“堆叠神经网络”使用的名称；也就是说，由多层组成的网络。

比赛本身涉及许多步骤，每个步骤都类似于之前和之后的步骤。就像跑步者一样，我们会一遍又一遍地进行重复的动作以到达终点。神经网络的每一步都涉及猜测、误差测量和权重的轻微更新，以及对系数的增量调整，因为它慢慢学会关注最重要的特征。

这是因为神经网络是在无知中诞生的。它不知道哪些权重和偏差将最好地转换输入以做出正确的猜测。它必须从猜测开始，然后随着它从错误中学习，依次尝试做出更好的猜测。（您可以将神经网络视为科学方法的缩影，检验假设并再次尝试——只是它是蒙着眼睛的科学方法。或者像孩子一样：他们生来就知之甚少，并且通过接触生活经验，他们慢慢学会解决世界上的问题。对于神经网络，数据是唯一的经验。）

深度学习中学习的本质不外乎：根据模型产生的误差调整模型的权重，直到不能再减少误差。

