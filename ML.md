https://vdoc.pub/

https://www.pdfdrive.com/

# 机器学习理解和实践路径

---

线性建模:最小二乘法

在有着广泛应用的机器学习中，一个重要且普遍的问题是学习或者推断属性变量与相应的响应变量或目标变量之间的函数关系，使得对任何一个属性集合，我们可以预测其响应。例如，我们可能想要建立一个能够执行疾病诊断的模型。为了构建这个模型，需要使用一个数据集，这个数据集是从已知疾病状态（响应，健康或患病）的患者中得到的测量（属性，如血压、心率、体重等）的集合。在完全不同的例子中，我们希望给顾客提出建议。在这种情况下，我们能够建立一个关于某个顾客以前买过物品的描述（属性）和该顾客最终是否喜欢该产品（响应）的模型。这个模型可以帮助我们预测顾客可能喜欢的物品，并因此进行推荐。这一章将涉及许多更重要的应用领域。

13445760_机器学习基础教程

---

building-data-science-applications-with-fastapi-develop-manage-and-deploy-efficient-machine-learning-applications-with-python-1801079218-9781801079211

使用 Python 和FastAPI构建数据科学 API

* 11 NumPy 和 pandas简介
* 12 使用 scikit-learn 训练机器学习模型
* 13 分类数据 朴素贝叶斯模型 346
* 14 实施部署 预测端点 363


pandas 的主要目的是标记数据。

---

第二章 数据的管理和理解

机器学习与R语言

---

机器学习是关于设计自动从数据中提取有价值信息的算法。这里的重点是“自动”，即机器学习关注可应用于许多数据集的通用方法，同时产生有意义的东西。机器学习的核心是三个概念：数据、模型和学习

由于机器学习本质上是数据驱动的，因此数据是机器学习的核心 数据。机器学习的目标是设计通用方法从数据中提取有价值的模式，理想情况下不需要太多特定领域的专业知识。

们可以考虑两种理解机器学习数学的策略：

自下而上：构建从基础到更高级的概念。这通常是更多技术领域（例如数学）的首选方法。这种策略的优点是读者始终能够依赖他们以前学过的概念。不幸的是，对于从业者来说，许多基本概念本身并不是特别有趣，缺乏动力意味着大多数基本定义很快就会被遗忘。

自上而下：从实际需求向下钻取到更基本的需求。这种以目标为导向的方法的优点是，读者始终知道他们为什么需要研究特定的概念，并且有一条清晰的所需知识路径。这种策略的缺点是知识建立在可能不稳定的基础上，读者必须记住一组他们无法理解的单词。

学习自动化

Mathematics for machine learning

---

机器学习颠覆了传统编程：ML 不是向计算机发出指令，而是向计算机提供数据，并要求它弄清楚要做什么：

这种方法早在监督学习出现之前就已经被统计学家使用了。它被称为线性回归。“线性”意味着我们正在追踪一条直线而不是曲线，而“回归”是统计学家的说法：“找到两个变量之间的关系”。

然而，即使你坚持使用监督学习，你也有很多东西可以看，尤其是如果你喜欢计算机科学或统计学的话。虽然这本书专注于神经网络，但还有其他值得学习的算法，其中一些在特定情况下仍然比神经网络工作得更好。举几个例子，看看支持向量机和随机森林。

programming-machine-learning-from-coding-to-deep-learning

通过此书才开始深入机器学习深度学习的知识细节了

---

讨论倍受欢迎的分类器随机森林（Random forest）与支持向量机（Support vector machine，SVM）。

随机森林分类器属于建构于决策树之上的整体学习应用，每一个基本分类器都是一个决策树。这时我们心中就冒出一个疑问：随机森林跟以决策树为基本分类器构成的Bagging 有什么不同？最大的差异应该就是随机的部分，以决策树为基本分类器构成的Bagging 的Boostrap sampling 只有应用在列方向（观测值方向）；随机森林的bootstrap sampling 则是同时应用在列方向（观测值方向）与栏方向（变数方向）。

支持向量机则是一种利用最适化（Optimization）概念在模型的精确度以及推广能力（Generalization ability）中取得一个最佳平衡点的演算法，她在面对小样本，非线性与多维度的资料中广受欢迎。

支持向量机是一种最小化结构风险（Structural risk）的演算法，何谓结构型风险？机器学习的内涵在于假设一个类似模型去逼近真实模型，而量化类似模型与真实模型之间差距的方式，跟我们在计算绩效（准确率）用的概念是相同的，我们用类似模型预测的结果去跟答案比较。许多的分类器可以在训练资料上达到很高的正确率（称作Overfitting），但是却失去应用在实际问题的推广能力（Generalization ability）。

资料科学家将分类器在训练样本可能过度配适的风险称为Empirical risk，分类器的推广能力不足的风险称为Generalization risk，两者的总和即为结构风险，而支持向量机就是在两者之间取得最佳平衡点，进而得到一个在训练资料绩效不错，亦能推广适用的类似模型。

https://ithelp.ithome.com.tw/articles/10187569

---

您无法比较，因为它们是不同类别的事物。深度学习为物体识别、物体分割、图像分类等复杂问题提供了完整的解决方案。SVM 只是一个分类器。分类器只是深度学习系统的一个组成部分，几乎总是以“神经网络”的形式出现。

它们基本上是完全不相关的。深度学习通过进行矩阵乘法来学习一系列非线性变换，然后将其输入到 ReLU 等“激活函数”中。SVM 根据类应该远离边界的标准找到一组“支持向量”或数据点，它们位于并定义决策边界附近。

深度学习是以分层方式学习越来越抽象的表示。每层都从下一层馈送，然后将输出发送到上一层，依此类推。在视觉应用的情况下，这个过程导致层次较高的神经元对特定的完整对象或场景敏感。

另一方面，支持向量机 (SVM) 是基于找到离任一侧最近点（支持向量）尽可能远的分裂边界（线性可分情况下的超平面）。换句话说，给定一组属于 A 和 B 两个类中的任何一个的点。SVM 是关于找到通过点之间的边界，例如将空间划分为 A 侧和 B 侧，同时保持最大距离远离任何一侧最近的点。靠近决策边界的那些点被称为支持向量，因为它们是“支持”边界的那些点。仅支持向量用于计算边界。支持向量机也可以以分层方式堆叠，形成支持向量机网络的深层变体。因此，DL 基于这种堆叠层这一事实意味着可以制作一个充满 SVM 的深度神经网络。

https://www.quora.com/What-is-the-difference-between-deep-learning-and-SVM
